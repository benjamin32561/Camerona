{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SSD_SKU110K.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"fRY24fGs6thP"},"source":["!gdown --id 1T4xmNRhe9halt0M0RFfqbFwhvV6kK7Mi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8qd9YMvWHWn"},"source":["!gdown --id 1-VyBD6fAnIb_ugEjJIDcCmkZcONENm8H"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N4NeLfYpEfz0"},"source":["!tar -xvf SKU110K_fixed.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7m22a_0bAPjM"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kFD6TiXO2CZO"},"source":["## Importing Libraries\n"]},{"cell_type":"code","metadata":{"id":"Lg-4jaxUvJyF"},"source":["from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7I4QJv6H_FAw"},"source":["## Constants"]},{"cell_type":"code","metadata":{"id":"vhZnLSvE_Eft"},"source":["hImage, wImage = 1024, 1024\n","nClasses = 1\n","batch_size = 1\n","epochs = 10\n","\n","feature_layers = [128, 64, 32, 16, 14, 12]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6dTC9CSg271v"},"source":["### Pre Processing image and label"]},{"cell_type":"code","metadata":{"id":"idOf0kZNH0Jf"},"source":["def pre_process_data(path):\n","  colnames=['Img','x','y','w','h',\\\n","            'class','ImgW','ImgH']\n","  \n","  annotate_data=pd.read_csv(path)\n","  tokenizer = tf.keras.preprocessing.text.Tokenizer()\n","  tokenizer.fit_on_texts(annotate_data['class'])\n","  idx=tokenizer.word_index\n","  print(idx)\n","  annotate_data = annotate_data.astype({\"x1\": float,\\\n","                                        \"x2\": float,\\\n","                                        \"y1\": float,\\\n","                                        \"y2\": float})\n","\n","  #Resize bb according to image\n","  annotate_data.iloc[:,1]=(annotate_data.iloc\\\n","                           [:,1]*wImage)/annotate_data.iloc[:,6]\n","  annotate_data.iloc[:,2]=(annotate_data.iloc\\\n","                           [:,2]*hImage)/annotate_data.iloc[:,7]\n","  annotate_data.iloc[:,3]=(annotate_data.iloc\\\n","                           [:,3]*wImage)/annotate_data.iloc[:,6]\n","  annotate_data.iloc[:,4]=(annotate_data.iloc\\\n","                           [:,4]*hImage)/annotate_data.iloc[:,7]\n","  \n","  annotate_data.iloc[:,5]=idx['object']\n","  annotate_data['label']=annotate_data\\\n","  [['x1','y1','x2','y2','class']].to_numpy().tolist()\n","\n","  #Converting to x,y,w,h\n","  annotate_data.iloc[:,1]=(annotate_data.iloc\\\n","                           [:,1]+annotate_data.iloc[:,3])/2.0\n","  annotate_data.iloc[:,2]=(annotate_data.iloc\\\n","                           [:,2]+annotate_data.iloc[:,4])/2.0\n","  annotate_data.iloc[:,3]=(annotate_data.iloc\\\n","                           [:,3]-annotate_data.iloc[:,1])\n","  annotate_data.iloc[:,4]=(annotate_data.iloc\\\n","                           [:,4]-annotate_data.iloc[:,2])\n","  annotate_data['boxes_xywh']=annotate_data\\\n","  [['x1','y1','x2','y2','class']].to_numpy().tolist()\n","  annotate_data = annotate_data.groupby('image_name').\\\n","  aggregate(lambda tdf: tdf.tolist())\n","  return annotate_data\n","\n","val_path='/content/SKU110K/annotations/annotations_val.csv'\n","val_data=pre_process_data(val_path)\n","path='/content/SKU110K/annotations/annotations_train.csv'\n","data=pre_process_data(path)\n","test_path='/content/SKU110K/annotations/annotations_test.csv'\n","test_data=pre_process_data(test_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Gt2bClZcK9Y"},"source":["def read_img(img):\n","  with tf.io.gfile.GFile(img, 'rb') as fp:\n","    image = fp.read()\n","  return image"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rg8hAHf-1-F9"},"source":["###TF RECORDS"]},{"cell_type":"code","metadata":{"id":"awo67XjvtuqM"},"source":["def wrap_bytes(img):\n","  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[img]))\n","\n","def wrap_float(value):\n","  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n","\n","def convert_tfrecord(images,labels,out_path):\n","  root='/content/SKU110K/images'\n","  with tf.io.TFRecordWriter(out_path) as writer:\n","    for i in range(len(images)):\n","      image=os.path.join(root,images[i])\n","      img_bytes=read_img(image)\n","      sku={\n","            'image':wrap_bytes(img_bytes),\n","            'x':wrap_float(np.array(labels[i])[:,0]),\n","            'y':wrap_float(np.array(labels[i])[:,1]),\n","            'w':wrap_float(np.array(labels[i])[:,2]),\n","            'h':wrap_float(np.array(labels[i])[:,3]),\n","            'class':wrap_float(np.array(labels[i])[:,4])\n","      }\n","      feature=tf.train.Features(feature=sku)\n","      example=tf.train.Example(features=feature)\n","      serialized=example.SerializeToString()\n","      writer.write(serialized)\n","\n","out_path='/content/val.tfrecords'\n","convert_tfrecord(val_data.index,val_data['label'],out_path)\n","\n","out_path='/content/train.tfrecords'\n","convert_tfrecord(data.index,data['label'],out_path)\n","\n","out_path='/content/test.tfrecords'\n","convert_tfrecord(test_data.index,test_data['label'],out_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rzUSt63mdre"},"source":["def imshow(image):\n","    plt.figure(figsize=(8, 8))\n","    plt.imshow(image)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EKjTcbaxmfqx"},"source":["def show_img(img,label):\n","  img = cv2.imread(img)\n","  color = (255,0,0)\n","  img = cv2.resize(img,(hImage,wImage))\n","  for i,val in enumerate(label):\n","    start = tuple((np.array(label[i][:2])).astype('int'))\n","    end = tuple((np.array(label[i][2:4])).astype('int'))\n","    cv2.rectangle(img,start,end,color,2)\n","  imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DScb1u85mhyj"},"source":["def convert_format(out,format):\n","  if format == 'x1y1x2y2':\n","    return tf.stack([out[...,0]-out[...,2]/2.0,\n","    out[...,1]-out[...,3]/2.0,\n","    out[...,0]+out[...,2]/2.0,\n","    out[...,1]+out[...,3]/2.0]\n","    ,axis=-1)\n","\n","  elif format == 'xywh':\n","    return tf.stack([(out[...,0]+out[...,2])/2.0,\n","    (out[...,1]+out[...,3])/2.0,\n","    out[...,2]-out[...,0],\n","    out[...,3]-out[...,1],\n","    out[...,4]],axis=-1)  ##sending the class also"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"up04se6ymoAn"},"source":["def convert_scale(matrix,scale):\n","  if scale == 'abs':\n","    return tf.stack([matrix[:,0]*wImage,\n","    matrix[:,1]*hImage,\n","    matrix[:,2]*wImage,\n","    matrix[:,3]*hImage],axis=-1)\n","\n","  elif scale == 'rel':\n","    return tf.stack([matrix[:,0]/wImage,\n","    matrix[:,1]/hImage,\n","    matrix[:,2]/wImage,\n","    matrix[:,3]/hImage],axis=-1)    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y66zwCtAmodA"},"source":["def normalised_ground_truth(matched_boxes,feature_box,return_format):\n","  matched_boxes = tf.cast(matched_boxes,dtype=tf.float32)\n","  feature_box = tf.cast(feature_box,dtype=tf.float32)\n","  if return_format == \"encode\":\n","    return tf.stack([(matched_boxes[:,0] - feature_box[:, 0]) / (feature_box[:, 2]),\n","                   (matched_boxes[:,1] - feature_box[:, 1]) / (feature_box[:, 3]),\n","        tf.math.log(matched_boxes[:,2] / feature_box[:, 2]),\n","        tf.math.log(matched_boxes[:,3] / feature_box[:, 3])],\n","        axis=-1) / [0.1, 0.1, 0.2, 0.2]\n","\n","  elif return_format == \"decode\":\n","    matched_boxes *= [0.1, 0.1, 0.2, 0.2]\n","    return tf.stack([matched_boxes[:,0] * feature_box[:, 2] + (feature_box[:, 0]),\n","                    matched_boxes[:,1] * feature_box[:, 3] + (feature_box[:, 1]),\n","          tf.math.exp(matched_boxes[:,2]) * feature_box[:, 2],\n","          tf.math.exp(matched_boxes[:,3]) * feature_box[:, 3]],\n","          axis=-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58kslIh3muE0"},"source":["def create_df_box(feature_layers):\n","#   s_min+(s_max-s_min)/(m-1)*(k-1)\n","#   s_min = 0.2\n","#   s_max = 0.9\n","#   m = 6\n","\n","#   scale=[]\n","#   for k in range(2,8):\n","#     sk = s_min+(s_max-s_min)/(m-1)*(k-1)\n","#     scale.append(sk)\n","#   scale.insert(0,s_min)\n","#   scale.extend([s_max])\n","\n","  scale =  [0.03, 0.05, 0.08, 0.12, 0.15, 0.25, 0.35]\n","\n","  feature_boxes=[]\n","  for feature_layer in feature_layers:\n","    if (feature_layer == 128 or feature_layer == 14 or feature_layer == 12):\n","    #   aspect_ratios=[1,2/3,1/2]\n","      aspect_ratios=[0.333, 0.416, 1.401]\n","\n","    else:\n","    #   aspect_ratios=[1,2/3,3/2,1/2,1/3]\n","      aspect_ratios=[0.416, 0.553, 0.722, 1.401, 3.131]\n","\n","    w_ar=[]\n","    h_ar=[]\n","    for i in aspect_ratios:\n","      if int(i) == 1:\n","        w=scale[feature_layers.index(feature_layer)]*np.sqrt(i)\n","        h=scale[feature_layers.index(feature_layer)]/np.sqrt(i)\n","        w_ar.append(w)\n","        h_ar.append(h)\n","        sk_1 = np.sqrt(scale[feature_layers.index(feature_layer)]* \n","                     scale[feature_layers.index(feature_layer)+1])\n","        w = sk_1*np.sqrt(i)\n","        h = sk_1/np.sqrt(i)      \n","      else:\n","        w = scale[feature_layers.index(feature_layer)]*np.sqrt(i)\n","        h = scale[feature_layers.index(feature_layer)]/np.sqrt(i)\n","      w_ar.append(w)\n","      h_ar.append(h)\n","  \n","    x_axis = np.linspace(0,feature_layer,feature_layer+1)\n","    y_axis=np.linspace(0,feature_layer,feature_layer+1)\n","    xx,yy = np.meshgrid(x_axis,y_axis)\n","    x = [(i+0.5)/(feature_layer) for i in xx[:-1,:-1]]\n","    y = [(i+0.5)/(feature_layer) for i in yy[:-1,:-1]]\n","\n","    if (feature_layer == 128 or feature_layer == 14 or feature_layer == 12):\n","      ndf_box = 4\n","    else:\n","      ndf_box = 6\n","    ndf_boxes = feature_layer*feature_layer*ndf_box\n","    nbox_coordinates = 4\n","    feature_box = np.zeros((ndf_boxes,nbox_coordinates))\n","    x = np.array(x).reshape(feature_layer*feature_layer)\n","    x = np.repeat(x,ndf_box)\n","    y = np.array(y).reshape(feature_layer*feature_layer)\n","    y = np.repeat(y,ndf_box)\n","\n","    w_ar = np.tile(w_ar,feature_layer*feature_layer)\n","    h_ar = np.tile(h_ar,feature_layer*feature_layer)\n","    feature_box[:,0] = x\n","    feature_box[:,1] = y\n","    feature_box[:,2] = w_ar\n","    feature_box[:,3] = h_ar\n","    feature_boxes.append(feature_box)\n","  df_box = np.concatenate(feature_boxes,axis=0)\n","  return df_box"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kqkIqePkmxqz"},"source":["def iou(box1,box2):\n","  box1 = tf.cast(box1,dtype=tf.float32)\n","  box2 = tf.cast(box2,dtype=tf.float32)\n","  \n","  x1 = tf.math.maximum(box1[:,None,0],box2[:,0])\n","  y1 = tf.math.maximum(box1[:,None,1],box2[:,1])\n","  x2 = tf.math.minimum(box1[:,None,2],box2[:,2])\n","  y2 = tf.math.minimum(box1[:,None,3],box2[:,3])\n","  \n","  #Intersection area\n","  intersectionArea = tf.math.maximum(0.0,x2-x1)*tf.math.maximum(0.0,y2-y1)\n","\n","  #Union area\n","  box1Area = (box1[:,2]-box1[:,0])*(box1[:,3]-box1[:,1])\n","  box2Area = (box2[:,2]-box2[:,0])*(box2[:,3]-box2[:,1])\n","  \n","  unionArea = tf.math.maximum(1e-10,box1Area[:,None]+box2Area-intersectionArea)\n","  iou = intersectionArea/unionArea\n","  return tf.clip_by_value(iou,0.0,1.0)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pF9Qx-zgmziS"},"source":["def df_match(labels,iou_matrix):\n","  max_values = tf.reduce_max(iou_matrix,axis=1)\n","  max_idx = tf.math.argmax(iou_matrix,axis=1)\n","  matched = tf.cast(tf.math.greater_equal(max_values,0.5),\n","                  dtype=tf.float32)\n","  gt_box = tf.gather(labels,max_idx)\n","  return gt_box,matched"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bU9brkj4m1kv"},"source":["def pre_process_img(img,feature_box_conv,matched):\n","  img = cv2.imread(img)\n","  img = cv2.resize(img, (hImage,wImage), interpolation = cv2.INTER_AREA)\n","  color = (255,0,0)\n","  matched_idx = np.where(matched)\n","  for i in (matched_idx):\n","    for j in i:\n","      start = feature_box_conv[j,:2]\n","      end = feature_box_conv[j,2:4]\n","      start = tuple((start))\n","      end = tuple((end))\n","      cv2.rectangle(img,start,end,color,2)\n","  plt.title('Matched Boxes')\n","  imshow(img)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OyR1KEt2m6VA"},"source":["#Matched Boxes\n","def create_data(data):\n","  i = 180\n","  images,labels = data.iloc[i].name,data.iloc[i]['label']\n","  # labels  x1y1x2y2\n","  root='/content/SKU110K/images'\n","\n","  images=os.path.join(root,images)\n","      \n","  #GT boxes creation\n","  img = images\n","  label = labels\n","  show_img(img,label)\n","  feature_box = create_df_box(feature_layers)\n","  feature_box = convert_scale(feature_box,'abs')\n","  feature_box_conv = convert_format(feature_box,'x1y1x2y2')\n","  iou_matrix = iou(feature_box_conv,np.array(label)[:,:4])\n","  gt_box,matched = df_match(convert_format(np.array(label),'xywh'),iou_matrix)\n","  # gt_box xywh\n","  print(tf.math.count_nonzero(matched))\n","  pre_process_img(img,convert_format(feature_box,'x1y1x2y2'),matched)\n","  boxes=gt_box[:,:4]\n","  classes = gt_box[:,4]\n","  classes = tf.cast(classes+1, dtype=tf.int32) #0 for background class\n","  matched = tf.cast(matched,dtype=tf.int32)\n","  classes = tf.cast(classes*matched,dtype=tf.int32)\n","  classes = tf.one_hot(classes,depth=nClasses+1,dtype=tf.float32)\n","  normalised_gtbox = normalised_ground_truth(boxes,feature_box,'encode')  \n","  normalised_gtbox = normalised_ground_truth(normalised_gtbox,feature_box,'decode')\n","  df_box = tf.concat((normalised_gtbox,classes),axis=-1)\n","  return df_box\n","\n","df_box = create_data(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWJgY8nKm_b1"},"source":["#label\n","feature_box = create_df_box(feature_layers)\n","feature_box = convert_scale(feature_box,'abs')\n","feature_box_conv = convert_format(feature_box,'x1y1x2y2')\n","\n","def main(label):\n","  iou_matrix = iou(feature_box_conv,label)\n","  gt_box,matched = df_match(convert_format(label,'xywh'),iou_matrix)\n","  boxes = gt_box[:,:4]\n","  classes = gt_box[:,4]\n","  \n","  classes = tf.cast(classes+1, dtype=tf.int32) #0 for background class\n","  matched = tf.cast(matched,dtype=tf.int32)\n","  classes = tf.cast(classes*matched,dtype=tf.int32)\n","  classes = tf.one_hot(classes,depth=nClasses+1,dtype=tf.float32)\n","  normalised_gtbox = normalised_ground_truth(boxes,feature_box,'encode')\n","  df_box = tf.concat((normalised_gtbox,classes),axis=-1)\n","  df_box.set_shape([feature_box.shape[0], 4+nClasses+1])\n","  return df_box\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-2EoYAtOnBYD"},"source":["def convert_back(serialized):  \n","  feature={\n","      'image':tf.io.FixedLenFeature([],tf.string),\n","      'x':tf.io.VarLenFeature(tf.float32),\n","      'y':tf.io.VarLenFeature(tf.float32),\n","      'w':tf.io.VarLenFeature(tf.float32),\n","      'h':tf.io.VarLenFeature(tf.float32),\n","      'class':tf.io.VarLenFeature(tf.float32)\n","  }\n","  parsed_example = tf.io.parse_single_example(serialized=serialized,\n","                                            features=feature)\n","  img = tf.io.decode_image(parsed_example['image'],channels=3)\n","  img.set_shape([None,None,3])\n","  img = tf.image.resize(img,[hImage, wImage])\n","  img = tf.cast(img,tf.float32)\n","  # normalize image \n","  img = tf.keras.applications.densenet.preprocess_input(img)\n","\n"," \n","  label=tf.stack([tf.sparse.to_dense(parsed_example['x']),\n","            tf.sparse.to_dense(parsed_example['y']),\n","            tf.sparse.to_dense(parsed_example['w']),\n","            tf.sparse.to_dense(parsed_example['h']),\n","            tf.sparse.to_dense(parsed_example['class']) - 1],axis=-1)\n","  # label\n","  df_box = main(label)\n","  return img, df_box\n","\n","\n","def data_gen(files):\n","  autotune = tf.data.experimental.AUTOTUNE\n","  dataset=tf.data.TFRecordDataset(filenames=files)\n","  dataset = dataset.map(convert_back, num_parallel_calls=autotune)\n","  dataset = dataset.apply(tf.data.experimental.ignore_errors())\n","  dataset = dataset.shuffle(16)\n","  dataset = dataset.batch(batch_size, drop_remainder=True)\n","  dataset = dataset.repeat(epochs)\n","  dataset = dataset.prefetch(autotune)\n","  return dataset\n","\n","test_files='/content/test.tfrecords'\n","test_dataset = data_gen(test_files)\n","\n","train_files='/content/train.tfrecords'\n","train_dataset = data_gen(train_files)\n","\n","val_files='/content/val.tfrecords'\n","val_dataset = data_gen(val_files)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBVQ16TdjsWL"},"source":["def total_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, dtype=tf.float32)\n","    y_pred = tf.cast(y_pred, dtype=tf.float32)\n","    pos_mask = tf.cast(tf.equal(tf.squeeze(y_true[:, :, 4:5], axis=-1), 0.0),\n","                       tf.float32)\n","    num_pos = tf.maximum(\n","        1.0, tf.cast(tf.math.count_nonzero(pos_mask, axis=-1), tf.float32))\n","    loc_loss = tf.compat.v1.losses.huber_loss(labels=y_true[:, :, :4],\n","                                              predictions=y_pred[:, :, :4],\n","                                              reduction=\"none\")\n","\n","    loc_loss = tf.reduce_sum(loc_loss, axis=-1)\n","    loc_loss = tf.where(tf.equal(pos_mask, 1.0), loc_loss, 0.0)\n","    loc_loss = tf.reduce_sum(loc_loss, axis=-1)\n","    loc_loss = loc_loss / num_pos\n","\n","    cce = tf.losses.CategoricalCrossentropy(from_logits=True,\n","                                            reduction=tf.losses.Reduction.NONE)\n","    cross_entropy = cce(y_true[:, :, 4:], y_pred[:, :, 4:])\n","\n","    #neg:pos 3:1\n","    num_neg = 3.0 * num_pos\n","\n","    #Negative Mining\n","    neg_cross_entropy = tf.where(tf.equal(pos_mask, 0.0), cross_entropy, 0.0)\n","    sorted_dfidx=tf.cast(tf.argsort(neg_cross_entropy,\\\n","                            direction='DESCENDING',axis=-1),tf.int32)\n","    rank = tf.cast(tf.argsort(sorted_dfidx, axis=-1), tf.int32)\n","    num_neg = tf.cast(num_neg, dtype=tf.int32)\n","    neg_loss = tf.where(rank < tf.expand_dims(num_neg, axis=1),\n","                        neg_cross_entropy, 0.0)\n","\n","    pos_loss = tf.where(tf.equal(pos_mask, 1.0), cross_entropy, 0.0)\n","    clas_loss = tf.reduce_sum(pos_loss + neg_loss, axis=-1)\n","    clas_loss = clas_loss / num_pos\n","    totalloss = loc_loss + clas_loss\n","    return totalloss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WxjCiYf-nIA9"},"source":["def conv_layer(filter,kernel_size,\n","               layer,strides=1,\n","               padding='same',\n","               activation='linear',pool=False,\n","               poolsize=2,poolstride=2,conv=True):\n","  if conv == True:\n","      layer = tf.keras.layers.Conv2D(filters=filter,\n","                                  kernel_size=kernel_size,\n","                                  strides=strides,\n","                                  activation=activation,\n","                                  padding=padding,\n","                                  kernel_initializer='he_normal')(layer)\n","      layer = tf.keras.layers.BatchNormalization()(layer)\n","      layer = tf.keras.layers.ReLU()(layer)\n","  elif pool == True:\n","    layer=tf.keras.layers.MaxPool2D(pool_size=(poolsize,poolsize),\n","                                    strides=poolstride,padding='same')(layer)\n","  return layer\n","\n","def ssd_model():\n","  outputs=[]\n","  densenet_121 = tf.keras.applications.DenseNet121(\n","                                            input_shape=(hImage, wImage, 3),\n","                                            include_top=False)\n","  \n","  #Feature Layer 1\n","\n","  layer = densenet_121.get_layer('pool3_relu').output\n","  output = tf.keras.layers.Conv2D(filters=4*(4+nClasses+1),\n","            kernel_size=3,\n","            padding='same',\n","            kernel_initializer='glorot_normal')(layer)\n","  output = tf.keras.layers.Reshape([-1, 4+nClasses+1])(output)\n","  outputs.append(output)\n","  \n","  #Feature Layer 2\n","\n","  layer = densenet_121.get_layer('pool4_relu').output\n","  output = tf.keras.layers.Conv2D(filters=6*(4+nClasses+1),\n","            kernel_size=3,\n","            padding='same',\n","            kernel_initializer='glorot_normal')(layer)\n","  output = tf.keras.layers.Reshape([-1, 4+nClasses+1])(output)\n","  outputs.append(output)\n","\n","\n","  #Feature Layer 3 \n","  \n","  layer = densenet_121.get_layer('relu').output\n","  output = tf.keras.layers.Conv2D(filters=6*(4+nClasses+1),\n","          kernel_size=3,\n","          padding='same',\n","          kernel_initializer='glorot_normal')(layer)\n","  output = tf.keras.layers.Reshape([-1, 4+nClasses+1])(output)\n","  outputs.append(output)\n","\n","  #Feature Layer 4\n","\n","  layer = conv_layer(128, 1, layer)\n","  layer = conv_layer(256, 3, layer, strides=2)\n","  output = tf.keras.layers.Conv2D(filters=6*(4+nClasses+1),\n","          kernel_size=3,\n","          padding='same',\n","          kernel_initializer='glorot_normal')(layer)\n","  output = tf.keras.layers.Reshape([-1, 4+nClasses+1])(output)\n","  outputs.append(output)\n","  \n","  #Feature Layer 5 \n","\n","  layer = conv_layer(128, 1, layer,padding= 'valid')\n","  layer = conv_layer(256, 3, layer,padding= 'valid')\n","  output = tf.keras.layers.Conv2D(filters=4*(4+nClasses+1),\n","          kernel_size=3,\n","          padding='same',\n","          kernel_initializer='glorot_normal')(layer)\n","  output = tf.keras.layers.Reshape([-1, 4+nClasses+1])(output)\n","  outputs.append(output)\n","                 \n","  #Feature Layer 6 \n","\n","  layer = conv_layer(128, 1, layer,padding= 'valid')\n","  layer = conv_layer(256, 3, layer,padding= 'valid')\n","  output = tf.keras.layers.Conv2D(filters=4*(4+nClasses+1),\n","        kernel_size=3,\n","        padding='same',\n","        kernel_initializer='glorot_normal')(layer)\n","  output = tf.keras.layers.Reshape([-1, 4+nClasses+1])(output)\n","  outputs.append(output)\n","\n","  out = tf.keras.layers.Concatenate(axis=1)(outputs)\n","  model = tf.keras.models.Model(densenet_121.input,out, name='SSD')\n","  model.summary()\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OxkdNC_3nJz6"},"source":["optimizer = tf.optimizers.Adam(1e-4)\n","\n","model = ssd_model()\n","\n","model.compile(optimizer=optimizer,\n","            loss=total_loss)\n","\n","callback=tf.keras.callbacks.ModelCheckpoint(\n","        filepath='/content/drive/My Drive/tanya/ssd_sku/ssd_model_{epoch:02d}.h5',\n","        monitor='loss',\n","        save_best_only=False,\n","        save_weights_only=True,\n","        mode='min',\n","        verbose=1)\n","\n","step_per_epoch = len(data)//batch_size\n","val_steps = len(val_data)//batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JisUcXgwnL57"},"source":["model.fit(train_dataset,           \n","          epochs=epochs,\n","          validation_data=val_dataset,\n","          steps_per_epoch=step_per_epoch,\n","          validation_steps=val_steps,\n","          callbacks=callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7MJcsIF-9xZT"},"source":["model.load_weights('/content/ssd_model_10.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ym6VsWzvnNmC"},"source":["def decode(y_pred,df_box):\n","  y_preds = tf.squeeze(y_pred,axis=0)\n","  df_box = tf.cast(df_box,dtype=tf.float32)\n","  boxes = y_preds[:,:4]\n","  boxes = normalised_ground_truth(boxes,df_box,'decode')\n","  boxes_x1y1 = convert_format(boxes,'x1y1x2y2')\n","  y_preds = tf.nn.softmax(y_preds[:,4:])\n","  cls_idx = tf.argmax(y_preds, axis=-1)\n","  cls_scores = tf.reduce_max(y_preds, axis=-1)\n","  #Filter out the backgrund class\n","  foreground_idx = tf.where(cls_idx != 0)[:, 0]\n","  print(foreground_idx.shape)\n","\n","  filtered_boxes = tf.gather(boxes_x1y1, foreground_idx)\n","  filtered_cls_idx = tf.gather(cls_idx, foreground_idx)\n","  filtered_cls_scores = tf.gather(cls_scores, foreground_idx)\n","  filtered_cls_idx = filtered_cls_idx-1\n","\n","  filtered_boxes_y1x1 = tf.stack([filtered_boxes[:,1],\n","                                filtered_boxes[:,0],\n","                                filtered_boxes[:,3],\n","                                filtered_boxes[:,2]],axis=-1)  \n","  nms_idx = tf.image.non_max_suppression(filtered_boxes_y1x1,\n","                                          filtered_cls_scores,\n","                                          max_output_size=200,\n","                                          iou_threshold=0.5,\n","                                          score_threshold=1e-2)\n","  final_boxes = tf.gather(filtered_boxes, nms_idx)\n","  final_cls_idx = tf.gather(filtered_cls_idx, nms_idx)\n","  final_cls_scores = tf.gather(filtered_cls_scores, nms_idx)\n","  return final_boxes, final_cls_idx, final_cls_scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYSB-KFQnPUW"},"source":["def visualize_detections(image, boxes, classes, scores):\n","  figsize=(7, 7)\n","  linewidth=1\n","  color=[0, 0, 1]\n","  image = np.array(image, dtype=np.uint8)\n","  plt.figure(figsize=figsize)\n","  plt.axis('off')\n","  plt.imshow(image)\n","  ax = plt.gca()\n","  for box, _cls, score in zip(boxes, classes, scores):\n","      text = '{}: {:.2f}'.format(_cls, score)\n","      x1, y1, x2, y2 = box\n","      w, h = x2 - x1, y2 - y1\n","      patch = plt.Rectangle([x1, y1], w, h, fill=False, \n","                            edgecolor=color, linewidth=linewidth)\n","      ax.add_patch(patch)\n","      ax.text(x1, y1, text, bbox={'facecolor':color, 'alpha':0.4}, \n","              clip_box=ax.clipbox, clip_on=True)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sedP7kNYnSqC"},"source":["class_map = {\n","    1: 'product'\n","}\n","for i in range(20, 30):\n","  image,label = test_data.iloc[i].name,test_data.iloc[i]['label']\n","  root='/content/SKU110K/images'\n","\n","  image_path=os.path.join(root,image)\n","  \n","  image = cv2.imread(image_path)\n","  image = cv2.resize(image, (hImage,wImage))\n","\n","  image_ = tf.keras.applications.densenet.preprocess_input(image)\n","\n","  label = main(np.array(label))\n","\n","  predictions = model(image_[None, ...], training=False)\n","  feature_box=create_df_box(feature_layers)\n","  feature_box=convert_scale(feature_box,'abs')\n","  final_boxes, final_cls_idx, final_cls_scores = decode(predictions,feature_box)\n","  visualize_detections(image, final_boxes, final_cls_idx, final_cls_scores)"],"execution_count":null,"outputs":[]}]}